Ключевые понятия, которые будем использовать в лабе: chroot, unshare, /sys/fs/cgroup/<our-cgroup-name>

ШАГ 1: Создаем директорию, копируем туда бинарь sh со всеми зависимостями
root@HOST3:/tmp# mkdir malutka
root@HOST3:/tmp# which sh
/usr/bin/sh
root@HOST3:/tmp# cp --parents /usr/bin/sh /tmp/malutka/
root@HOST3:/tmp# tree ./malutka/
root@HOST3:/tmp# tree malutka/
malutka/
└── usr
    └── bin
        └── sh
root@HOST3:/tmp# chroot ./malutka/ sh
chroot: failed to run command ‘sh’: No such file or directory ### ошибка возникает из-за отсуствия библиотек, от которых зависит sh
root@HOST3:/tmp# ldd /usr/bin/sh ### смотрим список зависимостей (ldd - list dynamic dependencies) 
	linux-vdso.so.1 (0x00007fffee56a000)
	libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007ced39c00000)
	/lib64/ld-linux-x86-64.so.2 (0x00007ced39e8f000)
root@HOST3:/tmp# tar ch /lib/x86_64-linux-gnu/libc.so.6 /lib64/ld-linux-x86-64.so.2 | tar x -C malutka/ (копируем через tar)
tar: Removing leading `/' from member names
tar: Removing leading `/' from hard link targets
root@HOST3:/tmp# tree malutka/
malutka/
├── lib
│   └── x86_64-linux-gnu
│       └── libc.so.6
├── lib64
│   └── ld-linux-x86-64.so.2
└── usr
    └── bin
        └── sh

6 directories, 3 files

ШАГ 2: Создаем протоконтейнер. Для начала изолируем наше дерево каталогов при помощи chroot

root@HOST3:/tmp# chroot ./malutka/ sh
# cd ..
# ls
sh: 2: ls: not found ### Видим, что в нашем протоконтейнере нет почти никаких команд. Для устранения этого недостатка создадим директорию malutka/bin и скачаем туда busybox
# pwd
/
# 

root@HOST3:/tmp/malutka# mkdir bin
root@HOST3:/tmp/malutka/bin# wget https://busybox.net/downloads/binaries/1.35.0-i686-linux-musl/busybox
root@HOST3:/tmp/malutka/bin# ls
busybox
root@HOST3:/tmp/malutka/bin# chmod +x busybox 
Запускаем chroot:
root@HOST3:/tmp/malutka/bin# chroot /tmp/malutka/ busybox sh
/ # ls
sh: ls: not found ### Видим, что краткое имя утилит не работает
/ # /bin/busybox ls
bin    lib    lib64  usr

Так же стоит обратить внимание на то, как процесс chroot находит бинарь:
root@HOST3:/tmp/malutka/bin# chroot /tmp/malutka/ /bin/busybox sh
То есть при запуске chroot файловый корень для текущего процесса переносится в /tmp/malutka и изнутри теперь виден как /. А дальше путь до бинаря относительно новой корневой системы каталогов будет /bin/busybox
/ # echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin ### Видим, что процесс для запуска бинаря использует переменную PATH относительно нового корня дерева каталогов. 
Устанавливаем символьные ссылки:
/ # /bin/busybox --install -s
/ # ls
bin      lib      lib64    linuxrc  usr



ШАГ 3:  Увеличиваем функционал протоконтейнера
Заметим, что в нашем протоконтейнере нет возможности наблюдать процессы:
/ # ps
PID   USER     TIME  COMMAND
ps: can't open '/proc': No such file or directory
Исправим это
/ # mkdir /proc
/ # mount -t proc none /proc
/ # ps
Мы видим все хостовые процессы, а не только процессы нашего прото-контейнера, потому что chroot изолирует только дерево каталогов, но не изолирует процессы или сеть.

Для создания контейнеров исползуются системные вызовы clone() и unshare(). Мы будем использовать одноименную утилиту unshare для нарезки неймспейсов под наш протоконтейнер
root@HOST3:/tmp/malutka/bin# unshare -mnp -f -R /tmp/malutka --mount-proc busybox sh ### параметры m = mount-namespace, n = network namespace, p = pid namespace, R = делает chroot на указанную директорию, f = fork создает дочерний процесс от нашей консоли уже в новом PID-namespace.
Без указания ключа f новый PID-namespace попробует примениться к текущему процессу консоли, что может вызвать конфликт.
/ # ps
PID   USER     TIME  COMMAND
    1 0         0:00 busybox sh
    2 0         0:00 ps

Почему нужно создавать отдельный mount-namespace? Почему нельзя ограничиться chroot?
Ответ: chroot меняет только корень файловой системы процесса и не изолирует дальнейшие точки монтирования. Я создал директорию /tmp/bol, в ней директории /proc, /proc1, /proc2
С двух терминалов сделал chroot в директорию /tmp/bol и по отдельности в каждом терминале ( то есть в двух разных процессах) смотнировал /proc, /proc1 в 1ом терминале  и /proc2 во втором. При этом все точик монтирования были доступны в двух этих процессах,
то есть не было изоляции по файловой системе.

Создадим новый контейнер
root@HOST3:/tmp/malutka/bin# unshare --mount --uts --ipc --net --pid --fork -f -R /tmp/malutka --mount-proc busybox sh
Нарежем для нашего контейнера cgroups:
root@HOST3:~# mkdir /sys/fs/cgroup/malutka/ ### Достаточно просто создать директорию для объявления новой cgroup.
root@HOST3:/sys/fs/cgroup/malutka# echo 524000 > /sys/fs/cgroup/malutka/memory.max ### Задаем ограничение по памяти
Добавим в эту контрольную группу главный процесс нашего контейнера:
root@HOST3:/sys/fs/cgroup/malutka# ps aux | grep busybox
root        7414  0.0  0.0   8292  1920 pts/1    S    15:59   0:00 unshare --mount --uts --ipc --net --pid --fork -f -R /tmp/malutka --mount-proc busybox sh
root        7415  0.0  0.0   1232   512 pts/1    S+   15:59   0:00 busybox sh
root        7545  0.0  0.0   9144  2176 pts/3    S+   16:05   0:00 grep --color=auto busybox
Наш главный процесс в контейнере это busybox sh PID 7414

root@HOST3:/sys/fs/cgroup/malutka# echo 7415 | tee /sys/fs/cgroup/malutka/cgroup.procs 
root@HOST3:/sys/fs/cgroup/malutka# cat /sys/fs/cgroup/malutka/cgroup.procs 
7415

Вернемся в терминал нашего процесса
Заполним оперативку контейнера:
/ # sh -c 'a=""; while true; do a="$a A" && echo $a; done'
unshare: sigprocmask unblock failed: Invalid argument ### ошибка возникает из-за SIGKILL дочернего процесса за превышение лимитов памяти 
root@HOST3:/sys/fs/cgroup/malutka# dmesg | grep oom
[13079.313301] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=malutka,mems_allowed=0,oom_memcg=/malutka,task_memcg=/malutka,task=busybox,pid=7837,uid=0
[13079.313316] Memory cgroup out of memory: Killed process 7837 (busybox) total-vm:1232kB, anon-rss:0kB, file-rss:512kB, shmem-rss:0kB, UID:0 pgtables:28kB oom_score_adj:200
Ура, мы создали контейнер.

СОЗДАНИЕ КОНТЕЙНЕРА С ПОМОЩЬЮ RUNC:
runc - это низкоуровневая утилита командной строки для создания и запуска контейнеров в Linux в соответствии со спецификацией Open Container Initiative (OCI). Она отвечает за непосредственное создание изолированных процессов с использованием возможностей ядра Linux (cgroups, namespaces), настройку корневой файловой системы и запуск контейнерных приложений.

Основные моменты про runc:
Это инструмент, который реализует спецификацию среды выполнения контейнеров OCI, обеспечивая стандартизированный запуск контейнеров.
runc создаёт cgroup, настраивает изоляцию через unshare, монтирует файловую систему контейнера и запускает процесс внутри этой изолированной среды.
Он является основой для многих современных систем контейнеризации, включая Docker, который использует runc для запуска контейнеров начиная с версии 1.11.
runc работает на уровне запуска контейнера, в отличие от более высокоуровневых инструментов (например, containerd), которые управляют жизненным циклом образов и контейнеров.
Таким образом, runc - это базовый runtime для контейнеров, который напрямую взаимодействует с ядром Linux для создания изолированных процессов и окружений, реализуя стандарты OCI.

Создадим директорию
root@HOST3:/tmp# mkdir debian-container
root@HOST3:/tmp# cd debian-container/
Выполним команду runc, для создания файла спецификации:
root@HOST3:/tmp/debian-container# runc spec
root@HOST3:/tmp/debian-container# ls
config.json
Ставим утилиту debootstrap
root@HOST3:/tmp/runc# apt-install debootstrap
Утилита debootstrap - это инструмент для установки минимальной базовой системы Debian (или производных, например, Ubuntu) в указанный каталог, не требующий инсталляционного CD и работающий напрямую с репозиториями Debian через интернет.
Зачем нужна debootstrap?
Позволяет развернуть минимальную систему Debian в подкаталоге уже работающей Linux-системы (например, для создания chroot-окружения или rootfs).
Используется для установки Debian на новый раздел или диск из другой ОС без необходимости загрузочного установщика.
Применяется для подготовки изолированных сред, контейнеров, виртуальных машин.
Поддерживает создание систем для разных архитектур (cross-debootstrapping).
Позволяет быстро получить "голую" систему с базовыми пакетами, которую затем можно донастроить вручную.
Как работает?
Загружает и распаковывает базовые пакеты Debian из выбранного репозитория в указанный каталог.
Можно указать релиз (например, stable, testing, sid) и архитектуру.
После установки базовой системы можно войти в неё через chroot и установить дополнительные пакеты.
Пример использования
bash
mkdir /stable-chroot
debootstrap stable /stable-chroot http://deb.debian.org/debian/
После этого в /stable-chroot будет минимальная Debian-система.
Таким образом, debootstrap - удобный и гибкий способ развернуть Debian-систему с нуля в любом каталоге, что полезно для установки, тестирования, создания контейнеров и других задач.

Ставим в директрию:
root@HOST3:/tmp/debian-container# debootstrap --variant=minbase --include iproute2 jammy rootfs
Параметры:
--variant=minbase - вариант установки, при котором разворачивается минимальный базовый набор пакетов, без дополнительных рекомендуемых и стандартных пакетов. Это даёт лёгкую, минимальную систему, на которой можно строить дальше.
--include iproute2 - дополнительно к базовому набору будет установлен пакет iproute2 (утилиты для управления сетью), который по умолчанию в minbase не включён.
jammy - кодовое имя релиза Ubuntu 22.04 LTS, то есть именно этот дистрибутив и версию будет развернуто.
rootfs - каталог, в который будет установлена минимальная система.





